getwd()
setwd("/Users/home/Desktop/submission")
getwd()
setwd("/Users/home/Desktop/Datathon")
library(dplyr)
library(stringr)
library(data.table)
zs_train <- read.csv("Training_Data.csv",header = T, stringsAsFactors = F)
zs_test <- read.csv("Testing_Data.csv",header = T, stringsAsFactors = F)
head(zs_train)
head(zs_test)
str(zs_train)
str(zs_test)
#checking data
summary(zs_train)
summary(zs_test)
terms      <- c('I', 'me', 'my')
term_regex <- paste0('(', paste(terms, collapse = '|'), ')')
tags <- as.character(zs_train$TRANS_CONV_TEXT)
for (i in 1:length(terms)) {
for (j in 1:nrow(zs_test)) {
#zs_train is the complete data from which you are trying to extract the text.
if(grepl(terms[i],zs_test[j,1]) == 1){zs_test[j,8] <- tags[i]
#Here is where you do an actual search
zs_test[j,9] <- 1
#Flag 1 to those observations where you find a match
}
}
}
zs_test["Output"] <- NA
zs_test["Output"] <-ifelse(zs_test[j,9],1,0)
fwrite(zs_test,"sol.csv", row.names = F)
View(zs_test)
library(reshape)
library(ggplot2)
library(tm)
library(wordcloud)
install.packages("reshape")
install.packages("worldcloud")
library(reshape)
library(ggplot2)
library(tm)
library(wordcloud)
zs_train <- read.csv("Training_Data.csv",header = T, stringsAsFactors = F)
zs_test <- read.csv("Testing_Data.csv",header = T, stringsAsFactors = F)
dataset_corpus <- lapply(zs_train, function(x) Corpus(VectorSource( toString(x) )))
# merge all documents into one single corpus
dataset_corpus_all <- dataset_corpus[[1]]
for (i in 2:length(unique_labels)) {
dataset_corpus_all <- c(dataset_corpus_all,dataset_corpus[[i]])
}
dataset_corpus <- lapply(zs_train, function(x) Corpus(VectorSource( toString(x) )))
# merge all documents into one single corpus
dataset_corpus_all <- dataset_corpus[[1]]
for (i in 2:length(zs_train)) {
dataset_corpus_all <- c(dataset_corpus_all,dataset_corpus[[i]])
}
dataset_corpus_all <- tm_map(dataset_corpus_all, removePunctuation)
# remove punctuation
dataset_corpus_all <- tm_map(dataset_corpus_all, removePunctuation)
# remove numbers
dataset_corpus_all <- tm_map(dataset_corpus_all, removeNumbers)
# remove stopwords
dataset_corpus_all <- tm_map(dataset_corpus_all, function(x) removeWords(x,stopwords("english")))
zs_test["Output"] <- NA
zs_train <- read.csv("Training_Data.csv",header = T, stringsAsFactors = F)
zs_test <- read.csv("Testing_Data.csv",header = T, stringsAsFactors = F)
head(zs_train)
head(zs_test)
str(zs_train)
str(zs_test)
#checking data
summary(zs_train)
summary(zs_test)
terms      <- c('I', 'me', 'my')
term_regex <- paste0('(', paste(terms, collapse = '|'), ')')
#Import the list of Keywords with first column as the keyword to match
tags <- as.character(zs_train$TRANS_CONV_TEXT)
for (i in 1:length(term_regex)) {
for (j in 1:nrow(zs_test)) {
#zs_train is the complete data from which you are trying to extract the text.
if(grepl(term_regex[i],zs_test[j,1]) == 1){zs_test[j,8] <- tags[i]
#Here is where you do an actual search
zs_test[j,9] <- 1
#Flag 1 to those observations where you find a match
}
}
}
t<-zs_train[!duplicated(zs_train[,c('Title','TRANS_CONV_TEXT')]),]
h <- left_join(zs_test, t)
sum(is.na(t))
mice_mod <- mice(t[, ], method='rf')
mice_output <- complete(mice_mod)
t <- mice_output
sum(is.na(t))
pre<-c('Title','TRANS_CONV_TEXT')
name<-c('Output')
model_gbm<-train(all.imp[,pre],all.imp[,name],method='gbm')
pred <- predict(object=model_gbm, solution[,pre])
summary(pred)
s$Buy_or_not<-ifelse(pred,1,0)
